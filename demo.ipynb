{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from config import get_config\n",
    "from model import MLPMixer, PatchEmbedding, Transformation1, Transformation2, MixerLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "config = get_config()\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(config[\"in_channels\"])], [0.5 for _ in range(config[\"in_channels\"])]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "# trainset = torchvision.datasets.MNIST(root=\"./mnist\", train=True, download=True, transform=transform)\n",
    "# testset = torchvision.datasets.MNIST(root=\"./mnist\", train=False, download=True, transform=transform)\n",
    "\n",
    "# CIFAR10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(1, 101, 1):\n",
    "  plt.subplot(10, 10, i)\n",
    "  # plt.imshow(trainset.data[i], cmap='gray')\n",
    "  plt.imshow(trainset.data[i])\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "- Input shape: `torch.Size([64, 1, 28, 28])`\n",
    "- Patch Embedding output shape: `torch.Size([64, 128, 7, 7])`\n",
    "- T2 transformation output shape: `torch.Size([64, 49, 128])`\n",
    "- T1 transformation output shape: `torch.Size([64, 128, 49])`\n",
    "- T1 transformation output shape: `torch.Size([64, 49, 128])`\n",
    "- Mixer Layer output shape: `torch.Size([64, 49, 128])`\n",
    "\n",
    "## CIFAR10\n",
    "\n",
    "- Input shape: `torch.Size([64, 3, 32, 32])`\n",
    "- Patch Embedding output shape: `torch.Size([64, 128, 8, 8])`\n",
    "- T2 transformation output shape: `torch.Size([64, 64, 128])`\n",
    "- T1 transformation output shape: `torch.Size([64, 128, 64])`\n",
    "- T1 transformation output shape: `torch.Size([64, 64, 128])`\n",
    "- Mixer Layer output shape: `torch.Size([64, 64, 128])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(64, 1, 28, 28) # MNIST (64, 1, 28, 28), CIFAR10 (64, 3, 32, 32)\n",
    "\n",
    "pe = PatchEmbedding(1, 128, 4) # MNIST (1, 128, 4), CIFAR10 (3, 128, 4) \n",
    "t1 = Transformation1()\n",
    "t2 = Transformation2()\n",
    "ml = MixerLayer(128, 49, 256, 256) # MNIST (128, 49, 256, 256), CIFAR10 (128, 64, 256, 256)\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "y1 = pe(X)\n",
    "print(f\"Patch Embedding output shape: {y1.shape}\")\n",
    "y2 = t2(y1)\n",
    "print(f\"T2 transformation output shape: {y2.shape}\")\n",
    "y3 = t1(y2)\n",
    "print(f\"T1 transformation output shape: {y3.shape}\")\n",
    "y4 = t1(y3)\n",
    "print(f\"T1 transformation output shape: {y4.shape}\")\n",
    "y5 = ml(y4)\n",
    "print(f\"Mixer Layer output shape: {y5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPMixer(in_channels=config[\"in_channels\"], image_size=config[\"image_size\"], patch_size=2, num_classes=10,\n",
    "                  embedding_dim=config[\"channel_dim\"], depth=config[\"depth\"], token_intermediate_dim=config[\"token_dim\"], channel_intermediate_dim=config[\"channel_dim\"]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy on training & test to see how good our model is\n",
    "def get_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            _, predictions = logits.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    model.train()\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for batch_index, (images, targets) in loop:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits = model(images)\n",
    "        loss =  criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {get_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {get_accuracy(test_loader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "Accuracy on training set: 99.54\n",
    "\n",
    "Accuracy on test set: 97.70\n",
    "\n",
    "## CIFAR10\n",
    "\n",
    "Accuracy on training set: 92.30\n",
    "\n",
    "Accuracy on test set: 59.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
